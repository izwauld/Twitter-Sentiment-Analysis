{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.3\n"
     ]
    }
   ],
   "source": [
    "#Should be version is 3.7.3.\n",
    "from platform import python_version\n",
    "\n",
    "print(\"Python version:\", python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "_cell_guid": "5cba9112-50d2-4d87-9b1a-226467f43322",
    "_uuid": "8fb26918-a44d-464f-ac33-7f98f06c5b4a",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "_cell_guid": "b0894518-2a41-4952-8b12-1a981dc1ecc3",
    "_uuid": "2b8bc89f-866c-4aa0-ba83-919cb8735ca8",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'NLP Disaster Tweets - Naive Bayes.ipynb',\n",
       " 'nlp-disaster-tweets-shallow-bilstm-w-attention.ipynb',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and testing data & display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "_cell_guid": "c2b85866-c000-4322-881c-f83948f72819",
    "_uuid": "201c1ab1-08e9-4928-8b48-ad19c52d7ade",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "_cell_guid": "818dfbeb-051e-44fa-9a19-a14438012a37",
    "_uuid": "588ce3e2-99ac-4fd0-abab-efcfbbff4e9e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7613 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} tweets\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the information content of the columns - specifically, how many null values are present in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "_cell_guid": "d82a6988-6450-475c-b093-7ca673dd0527",
    "_uuid": "adde0b1c-9adc-4f16-a6e1-606d539979ca",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for each column (% of total amount of data):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           0.0\n",
       "keyword      0.8\n",
       "location    33.3\n",
       "text         0.0\n",
       "target       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Null values for each column (% of total amount of data):\\n\")\n",
    "round(train_data.isnull().sum() / len(train_data) * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4cc0dcc1-c064-47a7-9400-f704bd9760f7",
    "_uuid": "ca2761ba-cbf5-4b7a-9cd5-45fd25682658"
   },
   "source": [
    "### Observations: \n",
    "* 30% of location are NaN. Location *may* indicate likelihood of disaster tweet (eg. in locations such as Syria, Afghan, etc.) more likely tweet is about a bombing, but still not always indicative. We will take the easy route and leave the location out for now.\n",
    "\n",
    "* Also, there is a very small percentage with missing keywords, so I will remove these entries for now too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "_cell_guid": "d62af9af-b0ba-48d1-b335-19b345fb9e80",
    "_uuid": "bfa6b5c2-4ebd-4240-a25a-4c846be250b0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(axis=0) # remove missing keyword entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for each column (% of total amount of data):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id          0.0\n",
       "keyword     0.0\n",
       "location    0.0\n",
       "text        0.0\n",
       "target      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Null values for each column (% of total amount of data):\\n\")\n",
    "(train_data.isnull().sum() / len(train_data)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3e00c1c7-9ae1-46a1-ad48-5d50e4979bd4",
    "_uuid": "97fadb98-4980-446d-9e80-01985bb49a98"
   },
   "source": [
    "### Since we are performing supervised classification with the BLSTM model, it is essential that we have as close to equal class balance as possible (this is not so important with the Naive Bayes model). So, let's check how balanced the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "_cell_guid": "742ed355-2f46-473b-a597-3ebe1c2044c5",
    "_uuid": "071cd8f7-ea45-4b69-b92b-20b0c0c1b8b9",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2884\n",
       "1    2196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target.value_counts() # Sample from majority class accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b71af074-8125-4b2f-9c46-9ace248cd12f",
    "_uuid": "6439e623-aec9-40f1-bc0a-67fb43e534a1"
   },
   "source": [
    "### So we have a slightly imbalanced 57-43 split of the data. Since there are plenty of observations for both classes (over 2000 for each), and the data is not wildly imbalanced (although that depends on who you ask) it may not be so necessary to balance the data. Nevertheless, we will do so here to ensure we have a perfectly equal split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "_cell_guid": "72a6936f-e160-44ad-ae71-a8f56a49f1ad",
    "_uuid": "0405c161-5921-49b0-8a7f-b149cb08a01f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_neg = train_data.target.value_counts()[0] # number of examples belonging to class 0\n",
    "num_pos = train_data.target.value_counts()[1] # number of examples belonging to class 1\n",
    "\n",
    "frac = num_pos / num_neg\n",
    "\n",
    "neg_data = train_data[train_data.target == 0].sample(frac=frac)\n",
    "pos_data = train_data[train_data.target == 1]\n",
    "\n",
    "new_train_data = pd.concat([pos_data, neg_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: We shuffle the new training dataset in order to better ensure a random mix of class labels, and less overfitting of our models to one particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataframe\n",
    "new_train_data = new_train_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are our balance issues fixed? (Hint: yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2196\n",
       "1    2196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in re-sampled dataframe: 4392\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tweets in re-sampled dataframe: {}\".format(len(new_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "_cell_guid": "097b73a6-0c81-40d9-95fe-378025385de6",
    "_uuid": "c9c15ead-e15b-4b01-84f0-0ab8555ad74b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets w/ #:  1066\n",
      "Number of tweets w/ @:  1199\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets w/ #: \", len([x for x in new_train_data.text.values if '#' in x])) # tweets with #\n",
    "print(\"Number of tweets w/ @: \", len([x for x in new_train_data.text.values if '@' in x])) # tweets with @"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quarter of the total tweets come with hashtags and just under a third come with @'s. Since this is such a large number, it might not be best to remove these tokens completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, we create the `clean_text` function which cleanses and standardizes the tweets into a form that is fit for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "_cell_guid": "35af6e20-0fce-426c-8eca-d540a452a5a2",
    "_uuid": "fdaa65d9-d9eb-48a6-9207-420e425c4c0b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    new_text = text.lower() # lowercase the text\n",
    "    new_text = re.sub(r\"\\w+\\:\\/\\/([a-z]+)\\.co\\/\\w+(\\n)?\", \"\", new_text) #remove urls\n",
    "    #new_text = re.sub(r\"@[a-zA-Z0-9]+(?:;)*\", \"\", new_text) # remove @s\n",
    "    #new_text = re.sub(r\"#\", \"\", new_text) # remove #s\n",
    "    new_text = re.sub(r\"[^a-z0-9A-Z]\", \" \", new_text) # remove non alphanumerics\n",
    "    new_text = re.sub(r\"[0-9]+[^\\w+]\", \"\", new_text) # remove words made wholy of digits\n",
    "    new_text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", new_text) # remove words w/ 1 char\n",
    "    new_text = re.sub(\" +\", \" \", new_text) # remove multiple consecutive spaces\n",
    "    \n",
    "    new_text = new_text.strip() # remove leading/trailing whitespaces\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "_cell_guid": "37ae6c53-54b1-48b7-af3f-85ef30172483",
    "_uuid": "6dcf2922-6d56-42ec-b9ca-8090891e057e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Greedy bastards @Fullscreen way to ruin creativity.  CENSORSHIP ON YOUTUBE: https://t.co/nMtlpO4B58',\n",
       "       'Is it seclusion when a class is evacuated and a child is left alone in the class to force compliance?  #MoreVoices',\n",
       "       '#FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/S4SiCMYRmH',\n",
       "       ...,\n",
       "       \"Couples having less sex... for fear it'll be a let down: Internet movies and books saying how sex 'ought to be' p\\x89Û_ http://t.co/c1xhIzPrAd\",\n",
       "       'The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7',\n",
       "       'Roosevelt Wash. under evacuation order due to wildfire http://t.co/FiJAPxyKRQ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.text.values # display some raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "_cell_guid": "1d148c11-edb8-40d3-874a-0d15d5ded20c",
    "_uuid": "31345f52-6b6d-49e7-9156-a18d25724df4",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @Caitsroberts see U the night wee bArra to get absolutely wrecked ????\n",
      "Cleaned:  caitsroberts see the night wee barra get absolutely wrecked\n"
     ]
    }
   ],
   "source": [
    "#Test cleaning on given tweet\n",
    "i = 6\n",
    "for tweet in new_train_data.text.values[i:]:\n",
    "    print(\"Original: \", tweet)\n",
    "    tweet = clean_text(tweet)\n",
    "    print(\"Cleaned: \", tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1eb759b-31dd-465b-95db-727b02f5e7b2",
    "_uuid": "bda82f71-0f3d-4b14-90e1-05c409a1c632"
   },
   "source": [
    "### Here, we preprocess the tweets using the `clean_text` function created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "_cell_guid": "b1732945-b163-4862-9f0f-c62d5c3e5898",
    "_uuid": "fbb9d9ab-dfcb-467f-b7c8-6ff1ee13c5c1",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tweets = {}\n",
    "for i, tweet in enumerate(new_train_data.text):\n",
    "    tweets[i] = clean_text(tweet)\n",
    "    \n",
    "labels = {}\n",
    "for i, label in enumerate(new_train_data.target):\n",
    "    labels[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d99b8036-305b-488a-865e-72da399e54d9",
    "_uuid": "cd5910ad-a8b1-4834-93d2-d978d2794e3c"
   },
   "source": [
    "### Data augmentation is a very important step in order to give your model more data to train on which can potentially improve performance. Here, we cleverly inflate the size of our training set by deleting a random word from each tweet, and adding the new tweet back into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "_cell_guid": "b20636e0-9017-41a8-a9fc-582b5db486a6",
    "_uuid": "bbd2ece7-ad06-4095-b330-c8b41a708178",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    temp, label = tweets[i], labels[i]\n",
    "    j = random.randint(0, len(temp.split())-1)\n",
    "    word = temp.split()[j]\n",
    "    temp = temp.replace(word, \"\")\n",
    "    temp = re.sub(\" +\", \" \", temp) # remove multiple consecutive spaces\n",
    "    temp = temp.strip() # remove leading/trailing whitespaces\n",
    "\n",
    "    tweets[len(tweets)] = temp\n",
    "    labels[len(labels)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77229a8c-0469-4c61-bce0-fe7d3774e44b",
    "_uuid": "66ad3ec4-ee50-4781-a577-cd43cbfb3642"
   },
   "source": [
    "### Now, we extract the tokens and lemmatize the tweets. In previous experiments, all English stopwords were excluded from the token list but no noticeable performance increase was observed.\n",
    "\n",
    "#### Note: Intuitively, stopwords (such as \"and,\" \"but,\" \"a\" etc.) convey little if any information when predicting sentiment, however it was found that removable of these words did not increase the performance of the model by any significant margin, so they were left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "_cell_guid": "ee243da9-4656-4e14-86f6-e9dfcaf421ea",
    "_uuid": "083da9a5-9f3d-40b1-92bd-8fdcda39ccfd",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lm = nltk.stem.WordNetLemmatizer()\n",
    "all_tokens = [item for _, value in tweets.items() for item in word_tokenize(value)]\n",
    "all_tokens_lm = [lm.lemmatize(t) for t in all_tokens]\n",
    "#all_tokens_lm = [lm.lemmatize(t) for t in all_tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a16e0ca8-506d-4cfa-b06c-0dd3a4f28858",
    "_uuid": "61812847-1691-4528-80d6-b3252b4643fc"
   },
   "source": [
    "### Get the number of tokens and vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "_cell_guid": "2522c3a0-c302-4e16-a2f8-61a8203d34a1",
    "_uuid": "c634d225-ee81-491b-8260-a2357ea44e49",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 95656 tokens after processing\n",
      "There are 10664 unique tokens after processing\n"
     ]
    }
   ],
   "source": [
    "N = len(all_tokens_lm)\n",
    "V = len(set(all_tokens_lm))\n",
    "        \n",
    "print(f\"There are {N} tokens after processing\")\n",
    "print(f\"There are {V} unique tokens after processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, we create a model for extracting tweets of a user-defined sentiment from our corpus. This comes in handy for the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "_cell_guid": "bb23c4a0-d9ee-4601-a61f-67ef97bfb628",
    "_uuid": "7794eccb-be92-464e-9a1e-ac8a55161843",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_dict(tweets, sentiments, sent):\n",
    "    \"\"\"\n",
    "    Gets a dictionary with tweets of a certain sentiment\n",
    "    \n",
    "    Inputs:\n",
    "        tweets: dict, contains the tweets (key = ID, value = tweet)\n",
    "        sentiments: dict, contains the sentiments (key = ID, value = 0 or 1)\n",
    "        sent: string, the sentiment (1 for \"disaster\", 0 for \"non-disaster\")\n",
    "    \n",
    "    Note: tweets & sentiments need to have the same ID\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for key, value in tweets.items():\n",
    "        if sentiments[key] == sent:\n",
    "            new_dict[key] = value\n",
    "            \n",
    "    return new_dict\n",
    "\n",
    "def count_occurences(w, counts):\n",
    "    try:\n",
    "        return counts[w]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "_cell_guid": "02e6a50d-9062-4021-890b-ff456710d6f6",
    "_uuid": "39821456-a20e-4a7c-8712-454d6366da1f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'greedy bastards fullscreen way ruin creativity censorship youtube'),\n",
       " (4,\n",
       "  'also dont think sewing thought leather belt would work out that well lol'),\n",
       " (5, 'ideas food flattened'),\n",
       " (6, 'caitsroberts see the night wee barra get absolutely wrecked'),\n",
       " (7,\n",
       "  'just added some more fire the flames for saturday rick wonder will spinning guest set along with chachi'),\n",
       " (10,\n",
       "  'petchary but can say that either should displeased move five spots jamaica congrats the reggaeboyz'),\n",
       " (11, 'utahcanary sigh daily battle'),\n",
       " (13,\n",
       "  'officialtjonez your lost for words made new fan yours fam crazy skills beyond blessed keep blazing dude made love and respect'),\n",
       " (14,\n",
       "  'today was such hastle from getting drug tested blood drown out shot document filling'),\n",
       " (15,\n",
       "  'sirbrandonknt exactly that why the lesnar cena match from summerslam last year was great because brock annihilated guy who')]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing Functionality ### \n",
    "test = filter_dict(tweets, labels, 0) # extract tweets belonging to class 0\n",
    "list(test.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e6e9dae-eebc-46be-b4a2-f3c13e1e479e",
    "_uuid": "dcd2028a-5591-424a-a906-cd3016bff1f9"
   },
   "source": [
    "## Here, we build the Naive Bayes model with +k smoothing. \n",
    "\n",
    "The NB model is a \"bag of words\" model that will predict the most likely sentiment $c$ given the words $w$ in a tweet. Formally, we compute $P(c|w)$ = $c_{NB}$ using Bayes Rule:\n",
    "\n",
    "$c_{NB}$ = $argmax(log(P(c)) + \\sum_{i}(log(P(w_i|c)))$\n",
    "\n",
    "where\n",
    "\n",
    "$P(c)$: prior probability, = # of tweets of sentiment c / total number of tweets\n",
    "\n",
    "$P(w_i|c)$: likelihood (posterior), = count($w_i$) in all documents of class $c$ / number of words in docs of class $c$\n",
    "\n",
    "#### Note: The smoothing parameter was varied but any value of k>1 did not significantly increase performance; thus, k=1 was chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "_cell_guid": "277d2e5d-8e4d-4d39-a3e8-0392671bd1e9",
    "_uuid": "2ea5de73-c036-4eab-b23b-d9c7ba33d811",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    \"\"\"Naive Bayes with +k smoothing\"\"\"\n",
    "    def __init__(self, documents, sentiments):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            documents: dict, key = ID, value = tweet\n",
    "            sentiments: dict, key = ID, value = sentiment (1 or 0)\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.sentiments = sentiments\n",
    "        self.classes = list(set(self.sentiments.values()))\n",
    "        \n",
    "    def train(self, tokens, k):\n",
    "        logprior, lhoods, bigdoc = {}, {}, {c : [] for c in self.classes}\n",
    "        Ndoc = len(self.documents) \n",
    "        V = set(tokens)\n",
    "        for c in self.classes:\n",
    "            c_tweets = filter_dict(self.documents, self.sentiments, c)\n",
    "            Nc = len(c_tweets)\n",
    "            logprior[c] = np.log(Nc / Ndoc)\n",
    "            bigdoc[c] = [item for _, value in c_tweets.items() for item in word_tokenize(value)]\n",
    "            counts = Counter(bigdoc[c])\n",
    "            allw_count = {v:count_occurences(v, counts) for v in V}\n",
    "            likelihood = {}\n",
    "            for w in V:\n",
    "                w_count = allw_count[w]\n",
    "                likelihood[w] = np.log((w_count + k) / (len(bigdoc[c]) + k*len(V)))\n",
    "                \n",
    "            lhoods[c] = likelihood\n",
    "            \n",
    "            print(f\"Finished with class {c}\")\n",
    "        \n",
    "        print(\"\\nFinished training!\")\n",
    "        return logprior, lhoods\n",
    "    \n",
    "    def classify(self, tweet, tokens, prior, lhoods):\n",
    "        V = set(tokens)\n",
    "        probs = {}\n",
    "        tweet = word_tokenize(tweet)\n",
    "        for c in self.classes:\n",
    "            probs[c] = prior[c]\n",
    "            for i in range(len(tweet)):\n",
    "                word = tweet[i]\n",
    "                if word in V:\n",
    "                    probs[c] += lhoods[c][word]\n",
    "                    \n",
    "        return self.classes[np.argmax(list(probs.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "_cell_guid": "50a610ed-2b18-4ba7-9d18-1c8729ad98e2",
    "_uuid": "501b2c25-7d36-492c-a905-ec8833a41506",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [0, 1]\n",
      "Documents:  [(0, 'greedy bastards fullscreen way ruin creativity censorship youtube'), (1, 'seclusion when class evacuated and child left alone the class force compliance morevoices')]\n",
      "Sentiments:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "### Testing Class Functionality ###\n",
    "model = NaiveBayesClassifier(tweets, labels)\n",
    "print(\"Classes: \", model.classes)\n",
    "print(\"Documents: \", list(model.documents.items())[:2])\n",
    "print(\"Sentiments: \", list(model.sentiments.values())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data into train + validation sets. Here, a standard 60-20-20 training/validation/testing split is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "_cell_guid": "1e1d0047-169a-4bb9-b70f-1a54c79e0b1a",
    "_uuid": "880e521b-3ef6-4982-86b2-ed8d7f2a221b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#60-20-20 train-dev-test split\n",
    "\n",
    "cutoff = int(0.8*len(tweets))\n",
    "train_cutoff = int(0.6*len(tweets))\n",
    "\n",
    "train_set = dict(list(tweets.items())[:train_cutoff])\n",
    "train_labels = dict(list(labels.items())[:train_cutoff])\n",
    "\n",
    "validation_set = dict(list(tweets.items())[train_cutoff:cutoff])\n",
    "validation_labels = dict(list(labels.items())[train_cutoff:cutoff])\n",
    "\n",
    "test_set = dict(list(tweets.items())[cutoff:])\n",
    "test_labels = dict(list(labels.items())[cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "_cell_guid": "33410ccb-0468-4847-8e68-2b5de3b3ae0e",
    "_uuid": "26874a13-cdca-4e0a-981e-bc42586beac0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with class 0\n",
      "Finished with class 1\n",
      "\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "#For NB, we use only the training and testing set\n",
    "model = NaiveBayesClassifier(train_set, train_labels)\n",
    "prior, lhood = model.train(all_tokens_lm, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5c08861-3d9b-4feb-a71b-e2d367cf5353",
    "_uuid": "b57a66a1-5f5b-483f-a094-7dc6dd9f3042"
   },
   "source": [
    "### Here, we evaluate the model on the basis of the F1 score. An `evaluate` function is created below that takes in the parameters we got from the training step and uses them for inference with the testing set. The `f1_score` function from the scikit-learn library is an easy way to get the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "_cell_guid": "dcef4246-b7ed-47e8-a67b-ca7baad31dcf",
    "_uuid": "6d964df1-e014-4d4b-85fc-d2210dda9851",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(parameters):\n",
    "    prior, lhood = parameters\n",
    "    predictions = {k : model.classify(v, all_tokens_lm, prior, lhood) for k, v in test_set.items()}\n",
    "    score = f1_score(list(test_labels.values()), list(predictions.values()))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "_cell_guid": "7a5a9806-778d-4637-9661-3e21613fe7a2",
    "_uuid": "cb5196f7-699c-449e-9100-ca25f9b3106e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1-score: 0.8991150442477878\n"
     ]
    }
   ],
   "source": [
    "score_nb = evaluate((prior, lhood))\n",
    "\n",
    "print(f\"Naive Bayes F1-score: {score_nb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While the NB model achieves a pretty good result on the training set, it does not perform too well in practice. Part of the reason for this is that the model does not consider the context of the surrounding words and instead has its predictions based on frequentist statistics (ie. how frequently words occur in with particular sentiment labels and how often those labels occur in the dataset). It completely disregards language nuance and as a result fails to capture the meaning of words and sentences effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c6853fe-9328-4dc0-bd02-539b7fcf20a4",
    "_uuid": "d342e50f-2da5-4779-ab9a-540225dcef0a"
   },
   "source": [
    "### Try it out on custom tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "_cell_guid": "1f4c2e43-e4e8-4698-8e4c-55671d886653",
    "_uuid": "f050ecfa-df8f-4f91-b1a6-5383b39028d6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "linking_dict = {0: \"non-disaster\", 1: \"disaster\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "_cell_guid": "2ec93977-cd47-48f1-bbe9-a39d7b22197d",
    "_uuid": "2fa33032-e8c4-40e1-920e-2e1604402330",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tweet: Help, there's been an earthquake!\n",
      "The Naive Bayes model predicts that your tweet is disaster related.\n"
     ]
    }
   ],
   "source": [
    "tweet1 = \"Help, there's been an earthquake!\"\n",
    "tweet2 = \"Enjoying my time here in Mexico :)\"\n",
    "tweet3 = \"My legs are killing me!\"\n",
    "\n",
    "your_tweet = tweet1\n",
    "\n",
    "print(\"Your tweet:\", your_tweet)\n",
    "\n",
    "pred = linking_dict[model.classify(your_tweet, all_tokens_lm, prior, lhood)]\n",
    "print(\"The Naive Bayes model predicts that your tweet is {} related.\".format(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
