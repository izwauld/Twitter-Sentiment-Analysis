{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.3\n"
     ]
    }
   ],
   "source": [
    "#Should be version is 3.7.3.\n",
    "from platform import python_version\n",
    "\n",
    "print(\"Python version:\", python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "_cell_guid": "5cba9112-50d2-4d87-9b1a-226467f43322",
    "_uuid": "8fb26918-a44d-464f-ac33-7f98f06c5b4a",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "_cell_guid": "b0894518-2a41-4952-8b12-1a981dc1ecc3",
    "_uuid": "2b8bc89f-866c-4aa0-ba83-919cb8735ca8",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'NLP Disaster Tweets - Naive Bayes.ipynb',\n",
       " 'nlp-disaster-tweets-shallow-bilstm-w-attention.ipynb',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and testing data & display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "_cell_guid": "c2b85866-c000-4322-881c-f83948f72819",
    "_uuid": "201c1ab1-08e9-4928-8b48-ad19c52d7ade",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "_cell_guid": "818dfbeb-051e-44fa-9a19-a14438012a37",
    "_uuid": "588ce3e2-99ac-4fd0-abab-efcfbbff4e9e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7613 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} tweets\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the information content of the columns - specifically, how many null values are present in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "_cell_guid": "d82a6988-6450-475c-b093-7ca673dd0527",
    "_uuid": "adde0b1c-9adc-4f16-a6e1-606d539979ca",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for each column (% of total amount of data):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           0.0\n",
       "keyword      0.8\n",
       "location    33.3\n",
       "text         0.0\n",
       "target       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Null values for each column (% of total amount of data):\\n\")\n",
    "round(train_data.isnull().sum() / len(train_data) * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4cc0dcc1-c064-47a7-9400-f704bd9760f7",
    "_uuid": "ca2761ba-cbf5-4b7a-9cd5-45fd25682658"
   },
   "source": [
    "### Observations: \n",
    "* 30% of location are NaN. Location *may* indicate likelihood of disaster tweet (eg. in locations such as Syria, Afghan, etc.) more likely tweet is about a bombing, but still not always indicative. We will take the easy route and leave the location out for now.\n",
    "\n",
    "* Also, there is a very small percentage with missing keywords, so I will remove these entries for now too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "_cell_guid": "d62af9af-b0ba-48d1-b335-19b345fb9e80",
    "_uuid": "bfa6b5c2-4ebd-4240-a25a-4c846be250b0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(axis=0) # remove missing keyword entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for each column (% of total amount of data):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id          0.0\n",
       "keyword     0.0\n",
       "location    0.0\n",
       "text        0.0\n",
       "target      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Null values for each column (% of total amount of data):\\n\")\n",
    "(train_data.isnull().sum() / len(train_data)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3e00c1c7-9ae1-46a1-ad48-5d50e4979bd4",
    "_uuid": "97fadb98-4980-446d-9e80-01985bb49a98"
   },
   "source": [
    "Since we are performing supervised classification with the BLSTM model, it is essential that we have as close to equal class balance as possible (this is not so important with the Naive Bayes model). So, let's check how balanced the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "_cell_guid": "742ed355-2f46-473b-a597-3ebe1c2044c5",
    "_uuid": "071cd8f7-ea45-4b69-b92b-20b0c0c1b8b9",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2884\n",
       "1    2196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target.value_counts() # Sample from majority class accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b71af074-8125-4b2f-9c46-9ace248cd12f",
    "_uuid": "6439e623-aec9-40f1-bc0a-67fb43e534a1"
   },
   "source": [
    "So we have a slightly imbalanced 57-43 split of the data. Since there are plenty of observations for both classes (over 2000 for each), and the data is not wildly imbalanced (although that depends on who you ask) it may not be so necessary to balance the data. Nevertheless, we will do so here to ensure we have a perfectly equal split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "_cell_guid": "72a6936f-e160-44ad-ae71-a8f56a49f1ad",
    "_uuid": "0405c161-5921-49b0-8a7f-b149cb08a01f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_neg = train_data.target.value_counts()[0] # number of examples belonging to class 0\n",
    "num_pos = train_data.target.value_counts()[1] # number of examples belonging to class 1\n",
    "\n",
    "frac = num_pos / num_neg\n",
    "\n",
    "neg_data = train_data[train_data.target == 0].sample(frac=frac)\n",
    "pos_data = train_data[train_data.target == 1]\n",
    "\n",
    "new_train_data = pd.concat([pos_data, neg_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: We shuffle the new training dataset in order to better ensure a random mix of class labels, and less overfitting of our models to one particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataframe\n",
    "new_train_data = new_train_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are our balance issues fixed? (Hint: yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2196\n",
       "1    2196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in re-sampled dataframe: 4392\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tweets in re-sampled dataframe: {}\".format(len(new_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "_cell_guid": "097b73a6-0c81-40d9-95fe-378025385de6",
    "_uuid": "c9c15ead-e15b-4b01-84f0-0ab8555ad74b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets w/ #:  1068\n",
      "Number of tweets w/ @:  1236\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets w/ #: \", len([x for x in new_train_data.text.values if '#' in x])) # tweets with #\n",
    "print(\"Number of tweets w/ @: \", len([x for x in new_train_data.text.values if '@' in x])) # tweets with @"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quarter of the total tweets come with hashtags and just under a third come with @'s. Since this is not such an insignificant fraction, it might not be best to remove these tokens completely.\n",
    "\n",
    "To be clear, there are two choice we can make:\n",
    "* Remove the # and @ symbols but retain the associated text\n",
    "* Remove the # and @ symbols along with the associated text\n",
    "\n",
    "As it turns out, there is little difference between the two when it comes to the final model performance. The following processing steps will remove the # and @ symbols but will retain the associated text in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create the `clean_text` function which cleanses and standardizes the tweets into a form that is fit for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "_cell_guid": "35af6e20-0fce-426c-8eca-d540a452a5a2",
    "_uuid": "fdaa65d9-d9eb-48a6-9207-420e425c4c0b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    new_text = text.lower() # lowercase the text\n",
    "    new_text = re.sub(r\"\\w+\\:\\/\\/([a-z]+)\\.co\\/\\w+(\\n)?\", \"\", new_text) #remove urls\n",
    "    new_text = re.sub(r\"@[a-zA-Z0-9]+(?:;)*\", \"\", new_text) # remove @s\n",
    "    new_text = re.sub(r\"#\", \"\", new_text) # remove #s\n",
    "    new_text = re.sub(r\"[^a-z0-9A-Z]\", \" \", new_text) # remove non alphanumerics\n",
    "    new_text = re.sub(r\"[0-9]+[^\\w+]\", \"\", new_text) # remove words made wholy of digits\n",
    "    new_text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", new_text) # remove words w/ 1 char\n",
    "    new_text = re.sub(\" +\", \" \", new_text) # remove multiple consecutive spaces\n",
    "    \n",
    "    new_text = new_text.strip() # remove leading/trailing whitespaces\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "_cell_guid": "37ae6c53-54b1-48b7-af3f-85ef30172483",
    "_uuid": "6dcf2922-6d56-42ec-b9ca-8090891e057e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@JoseBasedGod I'm obliterate you to the shadow realm.\",\n",
       "       \"I presume my timeline will be inundated with 'soggy bottom' &amp; lashings of 'moist' tweets now! :-D\",\n",
       "       'AMBULANCE SPRINTER AUTOMATIC FRONTLINE VEHICLE CHOICE OF 14 LEZ COMPLIANT | eBay http://t.co/Kp2Lf4AuTe',\n",
       "       ..., '@Allahsfinest12 ...death to muslims',\n",
       "       'On holiday to relax sunbathe and drink ... Putting out bush fires? Not so much ?? #spain https://t.co/dRno7OKM21',\n",
       "       'watching it go up in flames'], dtype=object)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.text.values # display some raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "_cell_guid": "1d148c11-edb8-40d3-874a-0d15d5ded20c",
    "_uuid": "31345f52-6b6d-49e7-9156-a18d25724df4",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I spent 15 minutes lifting weights. 43 calories burned. #LoseIt\n",
      "Cleaned:  spent minutes lifting weights calories burned loseit\n"
     ]
    }
   ],
   "source": [
    "#Test cleaning on given tweet\n",
    "i = 6\n",
    "for tweet in new_train_data.text.values[i:]:\n",
    "    print(\"Original: \", tweet)\n",
    "    tweet = clean_text(tweet)\n",
    "    print(\"Cleaned: \", tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1eb759b-31dd-465b-95db-727b02f5e7b2",
    "_uuid": "bda82f71-0f3d-4b14-90e1-05c409a1c632"
   },
   "source": [
    "Here, we preprocess the tweets using the `clean_text` function created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "_cell_guid": "b1732945-b163-4862-9f0f-c62d5c3e5898",
    "_uuid": "fbb9d9ab-dfcb-467f-b7c8-6ff1ee13c5c1",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tweets = {}\n",
    "for i, tweet in enumerate(new_train_data.text):\n",
    "    tweets[i] = clean_text(tweet)\n",
    "    \n",
    "labels = {}\n",
    "for i, label in enumerate(new_train_data.target):\n",
    "    labels[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d99b8036-305b-488a-865e-72da399e54d9",
    "_uuid": "cd5910ad-a8b1-4834-93d2-d978d2794e3c"
   },
   "source": [
    "Data augmentation is a very important step in order to give your model more data to train on which can potentially improve performance. Here, we cleverly inflate the size of our training set by deleting a random word from each tweet, and adding the new tweet back into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "_cell_guid": "b20636e0-9017-41a8-a9fc-582b5db486a6",
    "_uuid": "bbd2ece7-ad06-4095-b330-c8b41a708178",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    temp, label = tweets[i], labels[i]\n",
    "    j = random.randint(0, len(temp.split())-1)\n",
    "    word = temp.split()[j]\n",
    "    temp = temp.replace(word, \"\")\n",
    "    temp = re.sub(\" +\", \" \", temp) # remove multiple consecutive spaces\n",
    "    temp = temp.strip() # remove leading/trailing whitespaces\n",
    "\n",
    "    tweets[len(tweets)] = temp\n",
    "    labels[len(labels)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77229a8c-0469-4c61-bce0-fe7d3774e44b",
    "_uuid": "66ad3ec4-ee50-4781-a577-cd43cbfb3642"
   },
   "source": [
    "Now, we extract the tokens and lemmatize the tweets. In previous experiments, all English stopwords were excluded from the token list but no noticeable performance increase was observed.\n",
    "\n",
    "Note: Intuitively, stopwords (such as \"and,\" \"but,\" \"a\" etc.) convey little if any information when predicting sentiment, however it was found that removable of these words did not increase the performance of the model by any significant margin, so they were left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "_cell_guid": "ee243da9-4656-4e14-86f6-e9dfcaf421ea",
    "_uuid": "083da9a5-9f3d-40b1-92bd-8fdcda39ccfd",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lm = nltk.stem.WordNetLemmatizer()\n",
    "all_tokens = [item for _, value in tweets.items() for item in word_tokenize(value)]\n",
    "all_tokens_lm = [lm.lemmatize(t) for t in all_tokens]\n",
    "#all_tokens_lm = [lm.lemmatize(t) for t in all_tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a16e0ca8-506d-4cfa-b06c-0dd3a4f28858",
    "_uuid": "61812847-1691-4528-80d6-b3252b4643fc"
   },
   "source": [
    "Get the number of tokens and vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "_cell_guid": "2522c3a0-c302-4e16-a2f8-61a8203d34a1",
    "_uuid": "c634d225-ee81-491b-8260-a2357ea44e49",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93206 tokens after processing\n",
      "There are 9414 unique tokens after processing\n"
     ]
    }
   ],
   "source": [
    "N = len(all_tokens_lm)\n",
    "V = len(set(all_tokens_lm))\n",
    "        \n",
    "print(f\"There are {N} tokens after processing\")\n",
    "print(f\"There are {V} unique tokens after processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a model for extracting tweets of a user-defined sentiment from our corpus. This comes in handy for the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "_cell_guid": "bb23c4a0-d9ee-4601-a61f-67ef97bfb628",
    "_uuid": "7794eccb-be92-464e-9a1e-ac8a55161843",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_dict(tweets, sentiments, sent):\n",
    "    \"\"\"\n",
    "    Gets a dictionary with tweets of a certain sentiment\n",
    "    \n",
    "    Inputs:\n",
    "        tweets: dict, contains the tweets (key = ID, value = tweet)\n",
    "        sentiments: dict, contains the sentiments (key = ID, value = 0 or 1)\n",
    "        sent: string, the sentiment (1 for \"disaster\", 0 for \"non-disaster\")\n",
    "    \n",
    "    Note: tweets & sentiments need to have the same ID\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for key, value in tweets.items():\n",
    "        if sentiments[key] == sent:\n",
    "            new_dict[key] = value\n",
    "            \n",
    "    return new_dict\n",
    "\n",
    "def count_occurences(w, counts):\n",
    "    try:\n",
    "        return counts[w]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "_cell_guid": "02e6a50d-9062-4021-890b-ff456710d6f6",
    "_uuid": "39821456-a20e-4a7c-8712-454d6366da1f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'obliterate you the shadow realm'),\n",
       " (1,\n",
       "  'presume timeline will inundated with soggy bottom amp lashings moist tweets now'),\n",
       " (2,\n",
       "  'ambulance sprinter automatic frontline vehicle choice lez compliant ebay'),\n",
       " (3, 'arsonist the legal system never forgets'),\n",
       " (5, 'goddess sweet lord collapse knees buckle'),\n",
       " (6, 'spent minutes lifting weights calories burned loseit'),\n",
       " (8,\n",
       "  'cat fatality utica pleasant amp holland ave black cat with white paws average size grass next north side road'),\n",
       " (9, 'thank you survived'),\n",
       " (12,\n",
       "  'even when was kid haha super late but folks used bash for that shit understand survived cancer but still cheated'),\n",
       " (14, 'general audience wounded families zenit the world seen from rome')]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing Functionality ### \n",
    "test = filter_dict(tweets, labels, 0) # extract tweets belonging to class 0\n",
    "list(test.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e6e9dae-eebc-46be-b4a2-f3c13e1e479e",
    "_uuid": "dcd2028a-5591-424a-a906-cd3016bff1f9"
   },
   "source": [
    "Here, we build the Naive Bayes model with +k smoothing. \n",
    "\n",
    "The NB model is a \"bag of words\" model that will predict the most likely sentiment $c$ given the words $w$ in a tweet. Formally, we compute $P(c|w)$ = $c_{NB}$ using Bayes Rule:\n",
    "\n",
    "$c_{NB}$ = $argmax(log(P(c)) + \\sum_{i}(log(P(w_i|c)))$\n",
    "\n",
    "where\n",
    "\n",
    "$P(c)$: prior probability, = # of tweets of sentiment c / total number of tweets\n",
    "\n",
    "$P(w_i|c)$: likelihood (posterior), = count($w_i$) in all documents of class $c$ / number of words in docs of class $c$\n",
    "\n",
    "#### Note: The smoothing parameter was varied but any value of k>1 did not significantly increase performance; thus, k=1 was chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "_cell_guid": "277d2e5d-8e4d-4d39-a3e8-0392671bd1e9",
    "_uuid": "2ea5de73-c036-4eab-b23b-d9c7ba33d811",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    \"\"\"Naive Bayes with +k smoothing\"\"\"\n",
    "    def __init__(self, documents, sentiments):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            documents: dict, key = ID, value = tweet\n",
    "            sentiments: dict, key = ID, value = sentiment (1 or 0)\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.sentiments = sentiments\n",
    "        self.classes = list(set(self.sentiments.values()))\n",
    "        \n",
    "    def train(self, tokens, k):\n",
    "        logprior, lhoods, bigdoc = {}, {}, {c : [] for c in self.classes}\n",
    "        Ndoc = len(self.documents) \n",
    "        V = set(tokens)\n",
    "        for c in self.classes:\n",
    "            c_tweets = filter_dict(self.documents, self.sentiments, c)\n",
    "            Nc = len(c_tweets)\n",
    "            logprior[c] = np.log(Nc / Ndoc)\n",
    "            bigdoc[c] = [item for _, value in c_tweets.items() for item in word_tokenize(value)]\n",
    "            counts = Counter(bigdoc[c])\n",
    "            allw_count = {v:count_occurences(v, counts) for v in V}\n",
    "            likelihood = {}\n",
    "            for w in V:\n",
    "                w_count = allw_count[w]\n",
    "                likelihood[w] = np.log((w_count + k) / (len(bigdoc[c]) + k*len(V)))\n",
    "                \n",
    "            lhoods[c] = likelihood\n",
    "            \n",
    "            print(f\"Finished with class {c}\")\n",
    "        \n",
    "        print(\"\\nFinished training!\")\n",
    "        return logprior, lhoods\n",
    "    \n",
    "    def classify(self, tweet, tokens, prior, lhoods):\n",
    "        V = set(tokens)\n",
    "        probs = {}\n",
    "        tweet = word_tokenize(tweet)\n",
    "        for c in self.classes:\n",
    "            probs[c] = prior[c]\n",
    "            for i in range(len(tweet)):\n",
    "                word = tweet[i]\n",
    "                if word in V:\n",
    "                    probs[c] += lhoods[c][word]\n",
    "                    \n",
    "        return self.classes[np.argmax(list(probs.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "_cell_guid": "50a610ed-2b18-4ba7-9d18-1c8729ad98e2",
    "_uuid": "501b2c25-7d36-492c-a905-ec8833a41506",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [0, 1]\n",
      "Documents:  [(0, 'obliterate you the shadow realm'), (1, 'presume timeline will inundated with soggy bottom amp lashings moist tweets now')]\n",
      "Sentiments:  [0, 0]\n"
     ]
    }
   ],
   "source": [
    "### Testing Class Functionality ###\n",
    "model = NaiveBayesClassifier(tweets, labels)\n",
    "print(\"Classes: \", model.classes)\n",
    "print(\"Documents: \", list(model.documents.items())[:2])\n",
    "print(\"Sentiments: \", list(model.sentiments.values())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data into train + validation sets. Here, a standard 60-20-20 training/validation/testing split is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "_cell_guid": "1e1d0047-169a-4bb9-b70f-1a54c79e0b1a",
    "_uuid": "880e521b-3ef6-4982-86b2-ed8d7f2a221b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#60-20-20 train-dev-test split\n",
    "\n",
    "cutoff = int(0.8*len(tweets))\n",
    "train_cutoff = int(0.6*len(tweets))\n",
    "\n",
    "train_set = dict(list(tweets.items())[:train_cutoff])\n",
    "train_labels = dict(list(labels.items())[:train_cutoff])\n",
    "\n",
    "validation_set = dict(list(tweets.items())[train_cutoff:cutoff])\n",
    "validation_labels = dict(list(labels.items())[train_cutoff:cutoff])\n",
    "\n",
    "test_set = dict(list(tweets.items())[cutoff:])\n",
    "test_labels = dict(list(labels.items())[cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "_cell_guid": "33410ccb-0468-4847-8e68-2b5de3b3ae0e",
    "_uuid": "26874a13-cdca-4e0a-981e-bc42586beac0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with class 0\n",
      "Finished with class 1\n",
      "\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "#For NB, we use only the training and testing set\n",
    "model = NaiveBayesClassifier(train_set, train_labels)\n",
    "prior, lhood = model.train(all_tokens_lm, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5c08861-3d9b-4feb-a71b-e2d367cf5353",
    "_uuid": "b57a66a1-5f5b-483f-a094-7dc6dd9f3042"
   },
   "source": [
    "Here, we evaluate the model on the basis of the F1 score. An `evaluate` function is created below that takes in the parameters we got from the training step and uses them for inference with the testing set. The `f1_score` function from the scikit-learn library is an easy way to get the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "_cell_guid": "dcef4246-b7ed-47e8-a67b-ca7baad31dcf",
    "_uuid": "6d964df1-e014-4d4b-85fc-d2210dda9851",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(parameters):\n",
    "    prior, lhood = parameters\n",
    "    predictions = {k : model.classify(v, all_tokens_lm, prior, lhood) for k, v in test_set.items()}\n",
    "    score = f1_score(list(test_labels.values()), list(predictions.values()))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "_cell_guid": "7a5a9806-778d-4637-9661-3e21613fe7a2",
    "_uuid": "cb5196f7-699c-449e-9100-ca25f9b3106e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1-score: 0.8788968824940048\n"
     ]
    }
   ],
   "source": [
    "score_nb = evaluate((prior, lhood))\n",
    "\n",
    "print(f\"Naive Bayes F1-score: {score_nb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the NB model achieves a pretty good result on the training set, it does not perform too well in practice. Part of the reason for this is that the model does not consider the context of the surrounding words and instead has its predictions based on frequentist statistics (ie. how frequently words occur in with particular sentiment labels and how often those labels occur in the dataset). It completely disregards language nuance and as a result fails to capture the meaning of words and sentences effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c6853fe-9328-4dc0-bd02-539b7fcf20a4",
    "_uuid": "d342e50f-2da5-4779-ab9a-540225dcef0a"
   },
   "source": [
    "Try it out on custom tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "_cell_guid": "1f4c2e43-e4e8-4698-8e4c-55671d886653",
    "_uuid": "f050ecfa-df8f-4f91-b1a6-5383b39028d6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "linking_dict = {0: \"non-disaster\", 1: \"disaster\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "_cell_guid": "2ec93977-cd47-48f1-bbe9-a39d7b22197d",
    "_uuid": "2fa33032-e8c4-40e1-920e-2e1604402330",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tweet: Help, there's been an earthquake!\n",
      "The Naive Bayes model predicts that your tweet is disaster related.\n"
     ]
    }
   ],
   "source": [
    "tweet1 = \"Help, there's been an earthquake!\"\n",
    "tweet2 = \"Enjoying my time here in Mexico :)\"\n",
    "tweet3 = \"My legs are killing me!\"\n",
    "\n",
    "your_tweet = tweet1\n",
    "\n",
    "print(\"Your tweet:\", your_tweet)\n",
    "\n",
    "pred = linking_dict[model.classify(your_tweet, all_tokens_lm, prior, lhood)]\n",
    "print(\"The Naive Bayes model predicts that your tweet is {} related.\".format(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
